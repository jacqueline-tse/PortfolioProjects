{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94b8156-62ff-41ce-87a7-b6749f70f6f6",
   "metadata": {},
   "source": [
    "### What is the average price of properties that are currently on the market in RightMove?\n",
    "\n",
    "The goal of this project is to scrape the current property listings from the Rightmove website.\n",
    "\n",
    "Additional information in the form of the csv file 'location_data.csv' will be required. Along with the following details:\n",
    "\n",
    "location,location id,no of pages,mode\n",
    "cambridge,274,19,for-sale\n",
    "\n",
    "1. the location: the target location\n",
    "2. location id: a rightmove-specific identifier\n",
    "3. number of pages: the number of pages to be looked at\n",
    "4. mode: for generating the url and the file with the scraped data\n",
    "\n",
    "Four pieces of information on the properties are contained in the resulting data file, 'cambridge-for-sale.csv.'\n",
    "\n",
    "1. title\n",
    "2. address\n",
    "3. price\n",
    "4. seller's agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b7a70f-cce9-4120-b223-e4b4200d7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=0 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=24 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=48 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=72 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=96 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=120 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=144 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=168 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=192 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=216 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=240 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=264 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=288 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=312 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=336 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=360 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=384 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=408 | Status code: 200\n",
      "Fetching: https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274&index=432 | Status code: 200\n",
      "Write results to cambridge-for-sale.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "data = pd.read_csv('location_data.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "class RightmoveScraper:\n",
    "    results = []\n",
    "    where = ''\n",
    "       \n",
    "    def fetch(self, url):\n",
    "        print('Fetching: %s' % url, end ='')\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        print(' | Status code: %s' % response.status_code)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "\n",
    "    def parse(self, html):       \n",
    "        content = BeautifulSoup(html, 'html.parser')   #lxml\n",
    "        \n",
    "        titles = [title.text.strip() for title in content.findAll('h2', {'class': 'propertyCard-title'})]\n",
    "        addresses = [address['content'] for address in content.findAll('meta', {'itemprop': 'streetAddress'})]\n",
    "        #descriptions = [description.text for description in content.findAll('span', {'data-test': 'property-description'})]\n",
    "        prices = [price.text.strip() for price in content.findAll('div', {'class': 'propertyCard-priceValue'})]\n",
    "        #dates = [date.text.split()[-1] for date in content.findAll('span', {'class': 'propertyCard-branchSummary-addedOrReduced'})]\n",
    "        sellers = [seller.text.split('by')[-1].strip() for seller in content.findAll('span',{'class': 'propertyCard-branchSummary-branchName'})]\n",
    "                \n",
    "        for index in range(0, len(titles)):\n",
    "            self.results.append({\n",
    "                'title': titles[index],\n",
    "                'address': addresses[index],\n",
    "                #'description': descriptions[index],\n",
    "                'price': prices[index],\n",
    "                #'date': dates[index],\n",
    "                'seller': sellers[index]})\n",
    "                #'no_of_bedrooms' : bedrooms[index],\n",
    "                #'subtype': subtypes[index]})\n",
    "                \n",
    "        #print(self.results)\n",
    "\n",
    "\n",
    "    def to_csv(self, where, mode):\n",
    "        filename = where + '-' + mode + '.csv'\n",
    "        with open(filename,'w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file,fieldnames=self.results[0].keys())\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for row in self.results:\n",
    "                writer.writerow(row)\n",
    "               \n",
    "        print('Write results to {}'.format(filename))    \n",
    "               \n",
    "    def run(self):\n",
    "        for index, row in df.iterrows():\n",
    "            where = row['location']\n",
    "            location_id = row['location_id']\n",
    "            mode = row['mode']\n",
    "            no_of_pages = row['no_of_pages']\n",
    "            \n",
    "            for page in range(0, no_of_pages):\n",
    "                index = page * 24\n",
    "                url = 'https://www.rightmove.co.uk/property-' + str(mode) \\\n",
    "                        +'/find.html?locationIdentifier=REGION%5E' + str(location_id) \\\n",
    "                        +'&index=' + str(index)\n",
    "                #print (url)\n",
    "                \n",
    "                response = self.fetch(url)\n",
    "                self.parse(response.text)\n",
    "      \n",
    "            self.to_csv(where, mode)\n",
    "        \n",
    "        \"\"\"\n",
    "        ### Create a html file, so we can find out what came back from the website.        \n",
    "        #response = self.fetch('https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E274')\n",
    "\n",
    "        with open ('res.html', 'w', encoding='utf8', newline='') as html_file:\n",
    "            html_file.write(response.text)\n",
    "        \n",
    "\n",
    "        html = ''\n",
    "        with open ('res.html', 'r', encoding='utf8', newline='') as html_file:\n",
    "            for line in html_file:\n",
    "                html += html_file.read()\n",
    "                \n",
    "        self.parse(html)\n",
    "        self.to_csv(where)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    scraper = RightmoveScraper() \n",
    "    scraper.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e06825-05cb-45be-9e0f-6cc4de55668e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
